% Divide this into 2–3 sections
% -eg “Design/Architecture” and “Implementation” details
% -... but avoid generic section titles
% Start with high-level overview of solution (top-down)
% -Give the reader the bigger picture first
%-Figure with overview of system architecture works well
%-Roadmap helps as well
%Give examples and make them consistent (eg a running example)

\chapter{Interoperability Layer for Clinical Research Systems}

In this chapter we are presenting the solution for the first objective of the project:
setting up an interoperability layer for the main open-source clinical research systems, namely tranSMART, i2b2 and their respective derivations.
The general design of the solution is first presented, then the steps that are required to implement this system are explained.

\section{Design of the Solution}
This section describes in details the design of the solution chosen chapter~\ref{sec:sysdesign}. 
It aims to allow the cohort explorer UI Glowing Bear to support the following systems:
\begin{itemize}
    \item i2b2
    \item SHRINE 
    \item tranSMART 17.1 (REST API v2)
    \item tranSMART 16.2 (REST API v1)
\end{itemize}

Because of the fundamental differences in the APIs, it is not possible to browse at the same time. 
After being logged in, the user is able to choose from which resource do the queries.
A resource is defined as an instance of one the supported systems.

Figure~\ref{fig:sysdiagram} shows the system diagram after completion of the objective 1.
We can see that IRCT acts as a backend component for Glowing Bear, all its communications go through it using the PIC-SURE API.

\paragraph{Interoperability Layer}

\paragraph{Connectors}
what is supported for each connector
GB enable disable stuff

\paragraph{Authentication \& Authorization}
The authentication and authorization is delegated to a third-party using the OpenID Connect protocol~\cite{openidconnect}.

% note: present here solution with everything going through IRCT - if not OK in the end: change it back




Interoperability Layer for Clinical Research Systems
Common Interoperability Components
If IRCT: description of sources
Connectors
i2b2
SHRINE
(tranSMART 16.2)
(tranSMART 17.1)

exhaustive list of what

TODO: add impl step: enhance i2b2 capabilities (for counts and all), and also transmart



put the overall graph + two variants of transmart 17.1 with pic sure or not, if time allows
--> make those graphs

say that it wont query all the resources at once: some may support soem things or not 


\section{Implementation of the Design}
Here are described step-by-step the implementation of the solution presented in the last section. 
Each of the step first explains what is the current status of the relevant components, and then what needs to be modified or implemented.
roadmap todo
%nature of the thing-> should be test-driven


first target: most basic form, tree used to make queries


\subsection{Deploying Original Components}
First we are deploying an instance of IRCT, with an instance of i2b2 and tranSMART 16.2 which are both natively supported. 

gb
transmart 17.1

data loaded

how is it done etc.

1. irct setup + i2b2 + transmart 16.2 + shrine
deployment mainly, data? i2b2 demo data? fortransmart? 
DB setup for the systems
impl for shrine maybe? (extend the i2b2 one)

details of in appendix~\ref{sec:docker-images}


\subsection{Glowing Bear Modifications}
% todo: IN BACKGROUND: OVERVIEW OF PIC SURE API TO UNDERSTAND THIS PART

% GB modif overview + why no transmart rest v2
Glowing Bear is pretty heavily modified, the idea being to make it a native PIC-SURE API client by replacing completely the tranSMART client API implementation. 
Compatibility with tranSMART versions 17.1+ is later restored through the implementation of an IRCT resource interface (see~\ref{subsec:todo}).
The reasoning behind this choice is that maintaining compatibility of two different but similar APIs in Glowing Bear would be possible, but complicated, which translates into additional efforts spent on the implementation, and later on the maintenance of the code: this would be sub-optimal as these efforts are better spent elsewhere.
The potential downside of this choice is a time delay for the requests as we are introducing an additional middle-component, these will be formally measured in chapter~\ref{chap:perfeval}.

% overview of steps taken in GB workflow: steps for modifications
After reviewing what features will be removed from Glowing Bear, the organization of this section follows its typical workflow:
\begin{itemize}
    \item Client initialization: loading and login
    \item Explore the tree of concepts
    \item Step 1: Construct a query or re-use a saved query
    \item Save a constructed query
    \item Step 2: Select the data to export
    \item Step 3: Export the data
\end{itemize}

\subsubsection{Features Removal}

% studies
The tranSMART REST API v2 has several calls that are specific to studies, while the PIC-SURE API does not have a direct equivalent to this.
However the study can be seen as an additional dimension of the data, something that PIC-SURE supports.
Which means that this transition of studies to the more generic concept of dimension should also be applied in Glowing Bear, i.e. the behavior that is study specific should disappear and be replaced by a behavior specific to a dimension of the data. 
The following functions are removed:
\begin{itemize}
    \item \verb|ResourceService.getStudies()|
    \item \verb|getcountsperstudyandconcepts|
    \item \verb|getcount per study|
\end{itemize}

tree

get rid of it: study should just be a node in the tree 
what about cross-studies terms -> already ok from the tree transmart give?

constraints included in the ontology tree: do not exist in pic sure

study specific can be kept only if it doesnt interfere with the rest? check if that makes sense (can use attributes of ontolog)
maybe we can make it so that study specific things happens when it's there, but if not it's alright it still work (like visual attributes for i2b2)



- delete getStudies()
- isTreeNodeAStudy




\subsubsection{Initialization}

\paragraph{Authentication \& Authorization}
The modification to Glowing Bear is the migration from the authorization protocol OAuth2~\cite{oauth2} to the authentication and authorization protocol OpenID Connect~\cite{openidconnect}.
IRCT uses OpenID Connect to authenticate and authorize the users of its client applications, while Glowing Bear originally implements the client side of the OAuth2 protocol for authentication with tranSMART. 
Since OpenID Connect is a layer on top of OAuth2, the modifications to migrate the client code from OAuth2 to OpenID Connect are not significant, and are made by making use of the \emph{oidc-client-js} library~\cite{oidc-client-js}.
The flow remains the same: Glowing Bear obtains a JSON Web Token (JWT) from the OpenID Connect provider, which will then be embedded in the header of the HTTP requests to IRCT.

\paragraph{IRCT Resources Support}

% resources discovery

% enabling / disabling of features according to resource



PIC-SURE is more generic than the tranSMART API.

2.1. genericizes api talking within GB: keep compatibility with transmart rest v2: at the end working as before

\subsubsection{Enable disable feature of GB }
incl. the setting of a var of the current resource

features are not eactl disabled, but used only if resource suports it:
visualattributes
study (try)
irct resource object (from json received)



---
After a user has successfully logged in, the available resources and their capabilities are retrieved
Note the potential confusion between a PIC-SURE resource, and the resource service in Glowing Bear.

The function \verb|ResourceService.getResources()| is added to retrieve the PIC-SURE resources. 
It does the following API call:
\begin{verbatim}
GET /rest/resourceService/resources
\end{verbatim}

todo: redo exmaple with value predicate 
Response:
\begin{verbatim}
[
  {
    "id": 1,
    "name": "resource name (e.g. i2b2-local)",
    "implementation": "resource type (which implementation is used, e.g. i2b2XML)",
    "relationships": [ supported relationships between tree nodes, e.g. CHILD ],
    "logicaloperators": [ "AND", "OR", "NOT" ],
    "predicates": [ supported predicates and their properties, e.g.: {
        "predicateName": "predicate name (e.g. CONTAINS)",
        "displayName": "displayed name (e.g. Contains)",
        "description": "description",
        "default": true if this predicate should be selected by default,
        "fields": [ {
            "name": "field name (e.g. By Encounter)",
            "path": "field code (to be used in query, e.g. ENCOUNTER)",
            "description": "By Encounter",
            "required": true,
            "dataTypes": [ ],
            "permittedValues": [ "YES", "NO" ]
          } ],
        "dataTypes": [ data types to which this predicate applies (e.g. STRING) ],
        "paths": [ paths to which this predicate applies (empty for all) ]
      } ],
    "selectOperations": [ supported operations for select (e.g. AGGREGATE) ],
    "selectFields": [ supported fields for the operations, e.g. COUNT for AGGREGATE ],
    "joins": [ ],
    "sorts": [ ],
    "processes": [ ],
    "visualization": [ ],
    "dataTypes": [ data types and their properties, e.g.: {
        "name": "name of the data type",
        "pattern": "regex to validate the value",
        "description": "description of the data type"
    } ]
  }
]
    
\end{verbatim}


---
examples of calls and response given

\subparagraph{List of studies}
The list of available studies is requested:
\begin{verbatim}
GET /v2/studies
\end{verbatim}

Response:
\begin{verbatim}
{
  "studies": 
  [
    {
      "id": -20,
      "studyId": "CATEGORICAL_VALUES",
      "bioExperimentId": -10,
      "dimensions": 
      [
        "concept",
        "patient",
        "study"
      ]
    },
    ...
}
\end{verbatim}

\subparagraph{Query Terms Tree}
The tree of the queryable terms is recuperated, with a depth of 2:
\begin{verbatim}
GET /v2/tree_nodes?root=&depth=2&tags=true
\end{verbatim}

Response:
\begin{verbatim}
{
  "tree_nodes":
    [
      {
        "name":"Vital Signs",
        "fullName":"\Vital Signs\",
        "name":"Vital Signs",
        "type":"UNKNOWN",
        "visualAttributes": ["FOLDER","ACTIVE"], 
        "children": [
          {
            "name":"Heart Rate",
            "fullName":"\Vital Signs\Heart Rate\",
            "conceptCode":"VSIGN:HR",
            "conceptPath":"\Vital Signs\Heart Rate\",
            "name":"Heart Rate",
            "type":"NUMERIC",
            "visualAttributes":["LEAF","ACTIVE","NUMERICAL"],
            "constraint": {
              "type": "concept",
              "conceptCode": "VSIGN:HR"
            }
          }
        ]
      },
      ...
    ]
}
\end{verbatim}

\subparagraph{Saved Queries}
The list of previously saved queries is retrieved:
\begin{verbatim}
GET /v2/queries
\end{verbatim}

Response:
\begin{verbatim}
{
  "id": 1,
  "name": "testquery",
  "patientsQuery": {
    "constraint": {
      "args": 
      [
        {
          "conceptCode": "birthdate",
          "conceptPath": "\Demographics\Birth Date\",
          "fullName": "\Projects\Survey 1\Demographics\Birth Date\",
          "name": "Birth Date",
          "type": "concept",
          "valueType": "DATE"
        },
        {
          "studyId": "SURVEY1",
          "type": "study_name"
        }
      ],
      "type": "and"
    },
    "dimension": "patient",
    "type": "subselection"
  },
  "observationsQuery": {
    "data": [ ]
  },
  "apiVersion": "2.0",
  "bookmarked": false,
  "createDate": "2018-03-11T15:30:07Z",
  "updateDate": "2018-03-11T15:30:07Z"
}
\end{verbatim}


\subparagraph{Query}

\begin{verbatim}
POST /v2/observations/counts_per_study_and_concept

{
  "constraint": {
    "type": "or",
    "args": [
      {
        "type": "subselection",
        "dimension": "patient",
        "constraint": {
          "type": "and",
          "args": [
            {
              "type": "concept",
              "conceptCode": "birthdate"
            },
            {
              "type": "study_name",
              "studyId": "SURVEY1"
            }
          ]
        }
      },
      {
        "type": "subselection",
        "dimension": "patient",
        "constraint": {
          "type": "and",
          "args": [
            {
              "type": "concept",
              "conceptCode": "O1KP:CAT1"
            },
            {
              "type": "study_name",
              "studyId": "ORACLE_1000_PATIENT"
            }
          ]
        }
      }
    ]
  }
}
\end{verbatim}

getttreenodes used for 2 things: root and browsing


    


% \subsubsection{Generic API Calls}
% Originally Glowing Bear has an implementation of the tranSMART REST API v2, which must be replaced by the PIC-SURE API.
% In this the original implementation of the API is made generic using abstract classes. 
% This allows to easily switch between one or the other implementation. This has 2 purposes:
% Be able to switch back to the implementation of tranSMART without hassle, if it is needed later for something, or if later on something is discovered to be not OK.

% put it in folder in services

% Orignial impl: there are two types of functions, the ones that are common between APIs implementations: \verb|handleError()|, \verb|postCall()|, \verb|getCall()|, \verb|deleteCall()|, \verb|putCall()|
% And on the other end the ones that are specific to the API: \verb|logout()|, \verb|getStudies()|, \verb|getTreeNodes()|, \verb|getCountsPerStudyAndConcept()|, \verb|getCountsPerStudy()|, \verb|getCounts()|, \verb|getAggregate()|, \verb|getTrialVisits()|, \verb|getPedigreeRelationTypes()|, \verb|getExportDataFormat()|, \verb|getExportFileFormats()|, \verb|getExportJobs()|, \verb|createExportJob()|, \verb|runExportJob()|, \verb|downloadExportJob()|, \verb|cancelExportJob()|, \verb|archiveExportJob()|, \verb|getQueries()|, \verb|saveQuery()|, \verb|updateQuery()|, \verb|deleteQuery()|, \verb|savePatientSet()|.
% does this step make sense? given other modifs

% The common one are implemented in the abstract super-class ResourceService, while the specific ones are in the children classes \verb|TransmartRESTv2ResourceService| and \verb|PICSUREResourceService|.

% It is implemented as an Angular service in \verb|src/app/services/resource.service.ts|.






\subsubsection{Communications with the PIC-SURE API}
PIC SURE vocabulary: entity / concept
Here we will use the PIC-SURE vocabulary.

Implementation: change the names (concept -> entity)

Changes in Glowing Bear take root in the modification of the API calls, that are located in \verb|ResourceService|, this is thus what we take as starting points in this section. 

STEP 1: defining the where clauses (and a few count queries)
STEP 2: defining the SELECT clauses (what data do we want)


%Request: modify in resource service
%response: modify in models

\paragraph{Concepts Tree}

% modification of request (api call)
The function \verb|getTreeNodes()| is modified according to the following:
\begin{itemize}
    \item Parameters
    \begin{itemize}
        \item \verb|depth| is removed: PIC-SURE always return a depth of 1
        \item \verb|hasCounts| is removed: PIC-SURE always return a counts field (filling it or not depend on the resource implementation)
        \item \verb|hasTags| is removed: PIC-SURE always return nodes metadata (content is resource dependent)
        \item \verb|relationship| is added: tree browsing is generic in PIC-SURE, relationships between nodes are defined by resource, \verb|child| and \verb|parent| at least are supported
    \end{itemize}
    \item 
\end{itemize}

The API request becomes:
\begin{verbatim}
GET /rest/resourceService/path/<resource>/<path>/?relationship=<relationship>
\end{verbatim}

Response:
\begin{verbatim}
[
  {
    "pui": "/<resource>/<path>/",
    "name": "Concept internal name",
    "displayName": "Concept name",
    "description": "Concept description",
    "ontology": "Ontology Code",
    "ontologyId": "Concept ID in the ontology",
    "relationships": [],
    "counts": {},
    "dataType": {
      "name": "Data type name",
      "pattern": "Validation Regex",
      "description": "Data type description"
    },
    "attributes": {
      "visualattributes": "Visual attributes",
      "customAttributeName": "customAttributeValue"
    }
  },
  ...
]
\end{verbatim}

The \verb|dataType| field allows to know which constraints defined in the resource can be applied, thus what options can be presented to the user when a query is constructed.
The \verb|visualattributes| field allows to modify the appearance of the concept in the UI, for example if it's a folder containing concept, or a leaf node. 
Its presence is optional so if it is absent, the appearance will stay as it is by default.
The other fields can easily be mapped to original fields in Glowing Bear.

todo: count used?

% modification of response (model and calling code)
PIC-SURE does not support the loading of more concept than the direct children, i.e. a depth of 1 is supported.
We must then load in real-time the tree, as the user browses it.
It introduces a delay when navigating the tree, which could be mitigated by pre-loading in the background the tree, or making use of the customization abilities of IRCT, but this is left as a "nice-to-have" feature.

In \verb|TreeNodeService.loadTreeNodes()| the call to load iteratively load the nodes with \verb|loadTreeNext()| is removed, and only the top nodes are loaded.
\verb|loadTreeNext()| is modified to load only the direct children.
processTreenode extract from the json to put into TreeNode object -> modify

all the methods in the tree node service is modified to adapt to the structure of the PIC-SURE node. + the constraint service (is it for the query?)
from constraint: getTreeNodeDescendantsWithExcludedTypes / getConceptFromTreeNode / 
from query service : 
- updateProjectionTreeData : tree table? seems like it s for selectingv data in step 2 // shouldnt be modified normally
- updateTreeNodeCounts: update the counts with query results: shouldnt need modif
gb-projection component?
TreeNode represents a node: should be populated accordingly 

loadtree next on click

no model used, directl json
In TreeNodeService:
loadTreeNodes
loadtreenodes loads the root, then calls loadTreeNext to iteratively loads the whole tree with a default depth of 20

can't preload with a depth: either preload everything at startup, or load when click (compromise: load everything with a depth of 2 or 3 and then load at click)
currently: at click just the count is loaded


TreeNode is an interface: with the right fields the JSON object becomes this interface
function processTreeNode takes care of that --> can just be modified to fit either transmart or pic sure, easy
or the json is modified so htat it fits what GB is currently doing (and maybe what GB is currently doing can be enhanced) <<<< do that, avoid as much as possible to modify the stuff 

The function \verb|processTreeNode()|

constraints associated with the tree nodes: basically now 



QUERY: datatype


2.2. implements talking to pic sure: at the end working with both pic sure + transmart rest v2 
%-> keep compatiblity becasue that was the original discusion / try to get transmart 17.1 in irct but if not enough time this is as backup: describes only the solution with everythin thriough irct

study as a data type: exposed in the tree, and webclient knows how to process it 

\subsubsection{Queries}

% UI query construction (constraints)
When adding criterion at the step 1, the UI has to know what data type is the entity in order to ask the user more information. Here are the data types supported by Glowing Bear, and the parameters they support no it is the constrains
\begin{itemize}
    \item CONTAINS: no field
    \item 
\end{itemize}


most basic query: where with a PUI

select count 
-> dimension patient? what should be default? observations? 
-> no default: dimension always specified, because we want to count both patients and observation 
or the default is observation: and then dimension is specified 

MAKE USE OF DIMENSION TYPE

\verb|getCounts()| is merged in \verb|getAggregate()|: the aggregate call to PIC-SURE retrieves (if the resource support it) count, max, min, unique values and average. // concept? check now
As support for aggregate values is not mandatory for the resources, if the resource does not support it the related features are disabled (more info in section~\ref{sec:featuresdisable}.


The API request is:
\begin{verbatim}
POST /rest/queryService/runQuery
{
    clauseId: 
}
\end{verbatim}

Response:
\begin{verbatim}
[
  {
    "pui": "/<resource>/<path>/",
    "name": "Concept internal name",
    "displayName": "Concept name",
    "description": "Concept description",
    "ontology": "Ontology Code",
    "ontologyId": "Concept ID in the ontology",
    "relationships": [],
    "counts": {},
    "dataType": {
      "name": "Data type name",
      "pattern": "Validation Regex",
      "description": "Data type description"
    },
    "attributes": {
      "visualattributes": "Visual attributes",
      "customAttributeName": "customAttributeValue"
    }
  },
  ...
]
\end{verbatim}


the core: query

Example of PIC-SURE API query:

whereclause:
contains field, field contains pui and datatype, pui allows to creates entity
predicate is gotten
clausefields: map: path -> field

\begin{verbatim}
{
  "where": [ {
    "field": {
      "pui": "/nhanes/Demo/laboratory/laboratory/biochemistry/Creatinine, urine (mg per dL)/", 
      "dataType": "STRING"
    },
    "predicate": "CONTAINS"
    } ],
  "select": [ {
    "field": {
      "pui": "/nhanes/Demo/laboratory/laboratory/biochemistry/Creatinine, urine (mg per dL)/",
      "dataType": "STRING"
    },
  "alias": "Creatinine%2C%20urine%20%28mg%20per%20dL%29"
  } ]
}
\end{verbatim}

same principle for predicates: GB will support some but not all 

from transmart api: OK to use concept path
 "type": "concept",
                "path": "\\Public Studies\\EHR\\Diagnosis\\",

PREDICATE MANDATORY in query
-> CONTAINS predicate: simple exists ( no field ) --> this is the default predicate (put that in minimum stuff) or not necessarly? figure that out!



1 where clause + 1 predicate
multiple predicate: multiple where clause (linked with logical operator: how?)

QUERY UI:
when drag n dropping concept, we know what data type it is, we know which constrains can be applied on it, what is their name, validation regex, to construct the where constraint (like now)

also we 

DATA type is needed in query

select operation: for the aggregation


\subsubsection{Connectors}
- add support for shrine/medco with additional JAR packaged and put in wildfly
- add systems (by type) with pq-psql functions

resources modficiatons: add the agreggates (i2b2 just count, avg/min/max seems to be complicated? check it out)
i2b2: no select (currently), because it is mainly about the constraints: where clauses

importatn to specify what is done with minimal set of things supported

--> include datatype in query: saves a req to tree node
\paragraph{i2b2}

\paragraph{SHRINE}

\paragraph{tranSMART 16.2}

\paragraph{tranSMART 17.1}
last step is transmart 17.1 as connector, because it is if time allows


%\subsection{Current Status of Softwares}
%\subsection{Glowing Bear}
%desc of how it works

\section{pic sure api}
resource info in db -> example on how to do it with i2b2
through the api resourceService/resources get us all the resources and their capabilities(by type, but we want query for now i guess?)
define:
- predicates
- relationships
- the entities also define relationships, what is it exactly?
-> for GB we would need a minimum set of capabilities??

-> study should become just a parameter of the tree entity, but we shouldnt care about it
 -> how / at which stage implement that in Gb?

 edu.harvard.hms.dbmi.bd2k.irct.cl.rest;
 classes implementing the REST API, using javax.ws.rs / JAX-RS: Java API for RESTful Web Services
 


\section{Glowing Bear}
resource.service.ts -> this is what implements the api
study -> only use looks to be to restrict during query
then it can simply be another dimension of the data, as a constraint, but it is also in the tree, how to do that?
--> dimension exposed in the tree sounds good

subsec for mapping API calls
swubsec on how to implement change in API call: genericsize the calls, get the enabled/disabled features (methods to determine if enabled or not hardcoded), then change the actual things

---
at init: see what features is supported by the resource the user choose to use
get a list of features that are OK / not OK -- and TODO: add a step of implementing the disabling of some feature
sth else: seems quite a bit is studies based, this should be abstracted into the resource implementation

calls:
--- init step 0
1. /studies: list of studies, displayed under "Public Studies", some under "Private Studies" (distinction how??), and more, but how exactly are they mapped to the tree?

2. --> they are mapped with call to /tree\_nodes?root=\\ => each of the concept has a studyId to do the mapping
--> call to /tree\_nodes has also parameters depth --> IRCT only has depth 1, tree traversal in UI might need modifs

3. /queries: list of saved queries returned

4. /jobs: export jobs (running or not) --> not sure how IRCT handles that -> investigate / might need a change

5. /counts\_per\_study\_and\_concept: return counts for all studies / sub things -> see if how to map to irct, either as data or as process?

6. /counts: with param true, to display the total counts available

--- query step 1
7. /aggregates\_per\_concept : metadata of the concept, to display min max count etc. (aggregate data)
triggered on drag n drop of concept
--> use aggregate just as scidb again (so this should be a requirement of GB-or if not feature disabled)

POST /v2/observations/aggregates\_per\_concept
{constraint: {type: "concept", conceptCode: "O1KP:AGE"}}

{
  "aggregatesPerConcept": {
    "O1KP:AGE": {
      "numericalValueAggregates": {
        "avg": 51.25,
        "count": 1200,
        "max": 65.0,
        "min": 50.0,
        "stdDev": 4.147509477069983
      }
    }
  }
}

--> select aggregate
-> different category of feature enabled disabled is the min/max (because of i2b2) -> this should be quite fine grained, maybe directly associated to the specific function exposed by the resource

SELECT COUNT should be 1 call: no second call to get data


8. /elements: param contraint: which concept // not sure of what the answer if for?
GET /v2/dimensions/trial\%20visit/elements
constraint:{"type":"concept","conceptCode":"O1KP:AGE"}

{
  "elements": 
  [
    {
      "id": -101,
      "relTimeLabel": "General",
      "relTimeUnit": null,
      "relTime": null
    }
  ]
}


starting here possible to change constraints & concepts in UI, then click on update counts:
9. /counts\_per\_study\_and\_concept: update the counts according to the selected concepts-> return all relevant count (to update the tree) // constraint as param
POST /v2/observations/counts\_per\_study\_and\_concept
{
  "constraint": {
    "type": "subselection",
    "dimension": "patient",
    "constraint": {
      "type": "and",
      "args": [
        {
          "type": "and",
          "args": [
            {
              "type": "concept",
              "conceptCode": "O1KP:AGE"
            },
            {
              "type": "value",
              "valueType": "NUMERIC",
              "operator": ">=",
              "value": 55
            }
          ]
        },
        {
          "type": "study_name",
          "studyId": "ORACLE_1000_PATIENT"
        }
      ]
    }
  }
}

{
  "countsPerStudy": {
    "ORACLE_1000_PATIENT": {
      "O1KP:AGE": {
        "observationCount": 100,
        "patientCount": 100
      },
      "O1KP:CAT1": {
        "observationCount": 100,
        "patientCount": 100
      },
      "O1KP:CAT10": {
        "observationCount": 100,
        "patientCount": 100
      },
      ......
    }
  }
}

--> this would require a groupb by count basically? maybe that can be passed as a parameter of the select query
that's where to get this feature enabled, resource needs to have aggregate w/ count, and also another select parameter which for which concepts you want the counts

there is both counts per study, and counts per study and concepts / merge into 1 thing (study becomes a dimension)
implementation STEP study=dimension

so here, we use aggregate count, param the list of dimensions we wanna query-analog to modifier

/counts



---
runQuery: use POST /runQuery?only\_count&full\_response to get with 1 call the result
--- query step 2: about selecting data  / fields we wanna get from the selected patients / observations 

/file\_formats
/data\_formats


--- query step 3: data exports
-> check how it's done by irct

--- analysis! check out how it's done



some features might be disabled according to the availability of backend features

todo: put examples of how a transmart rest v2 query would be using irct, for all of them!




\section{irct}
version from github to select: which? there seem to be a new query param (commit on feb 2) only\_count, which may prove valuable for GB << important question to solve, check out a specific commit? last release is not recent enough as of now 

--> in the queryesrvice, when running query, there is a parameter "only\_count" that exists (in the later version)
it is added to the metadata of the query, to be processed by the RI (i guess support not mandatory) 
-> to have less processing, use it from GB!

select aggregate (count), they exist, check out: https://github.com/hms-dbmi/IRCT/blob/ae31f79ef2015bc6ae349e30e2a6652a22141b07/IRCT-RI/src/main/resources/SciDB.sql

aggregate is a type of select, and count is a type of aggregate, totally OK to do that 



---
\subsection{Resources}
does a lib in java to talk to transmart rest v2 exists? would be nice


todo: transmart cache the ontology because depth can be specified

implekmentaion of transmart: study as first layer? no just the tree presentede by transmart

define interface for java / sql skeleton for GlowingBearFeatureName (counts, etc.)