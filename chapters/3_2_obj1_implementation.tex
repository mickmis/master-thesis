\section{Implementation of the Interoperability Layer}
Here are described step-by-step the implementation of the solution presented in the last section. 
Each of the step first explains what is the current status of the relevant components, and then what needs to be modified or implemented.
% todo: nature of the thing-> should be test-driven
% todo: give a roadmap

\subsection{Deploying Original Components}
First we are deploying an instance of IRCT, with an instance of i2b2 and tranSMART 16.2 which are both natively supported. 

-> setup of the individual building blocks

gb
transmart 17.1

data loaded

how is it done etc.

1. irct setup + i2b2 + transmart 16.2 + shrine
deployment mainly, data? i2b2 demo data? fortransmart? 
DB setup for the systems
impl for shrine maybe? (extend the i2b2 one)

details of in appendix~\ref{sec:docker-images}


\subsection{Glowing Bear Modifications}

% GB modif overview + why no transmart rest v2
Glowing Bear is pretty heavily modified, the idea being to make it a native PIC-SURE API client by replacing completely the tranSMART client API implementation. 
Compatibility with tranSMART versions 17.1+ is later restored through the implementation of an IRCT resource interface (see~\ref{subsec:todo}).
The reasoning behind this choice is that maintaining compatibility of two different but similar APIs in Glowing Bear would be possible, but complicated, which translates into additional efforts spent on the implementation, and later on the maintenance of the code: this would be sub-optimal as these efforts are better spent elsewhere.
The potential downside of this choice is a time delay for the requests as we are introducing an additional middle-component, these will be formally measured in chapter~\ref{chap:perfeval}.

% overview of steps taken in GB workflow: steps for modifications
After reviewing what features will be removed from Glowing Bear, the organization of this section follows its typical workflow:
\begin{itemize}
    \item Client initialization: loading and login
    \item Explore the tree of concepts
    \item Step 1: Construct a query or re-use a saved query
    \item Save a constructed query
    \item Step 2: Select the data to export
    \item Step 3: Export the data
\end{itemize}

% todo: check, integrate or not
% PIC SURE vocabulary: entity / concept
% Here we will use the PIC-SURE vocabulary.
% Implementation: change the names (concept -> entity)
% Changes in Glowing Bear take root in the modification of the API calls, that are located in \verb|ResourceService|, this is thus what we take as starting points in this section. 
% STEP 1: defining the where clauses (and a few count queries)
% STEP 2: defining the SELECT clauses (what data do we want)
%Request: modify in resource service
%response: modify in models

% todo: map step 1=where, step 2= select, step 3=export (data tables new step 3, where?) // 



% --- text of previous version:
%The study can however be considered as a dimension of the observations, something that can be supported generically through PIC-SURE.
%Which means that this transition of studies to the more generic concept of dimension should also be applied in Glowing Bear, i.e. the behavior that is study specific should disappear.
%We rename the module \verb|gb-study-constraint| to \verb|gb-dimension-constraint| to handle constraints based on dimension, if the resource exposes such entities in its tree.
%In order to keep the name auto-completion feature, the list of possible values for the queried dimension is populated wiht the following query to PIC-SURE:
% \begin{verbatim}
% {
%   "select": [ {
%     "field": {
%       "pui": "/<resource>/<path_to_dimension_entity>",
%       "dataType": "DIMENSION"
%     },
%   "alias": "Creatinine%2C%20urine%20%28mg%20per%20dL%29"
%   } ]
% }
% \end{verbatim}


\subsubsection{Authentication \& Authorization}
% todo: possibly redo this part after feedback from ward

The modification to Glowing Bear is the migration from the authorization protocol OAuth2~\cite{oauth2} to the authentication and authorization protocol OpenID Connect~\cite{openidconnect}.
IRCT uses OpenID Connect to authenticate and authorize the users of its client applications, while Glowing Bear originally implements the client side of the OAuth2 protocol for authorization with tranSMART. 
Since OpenID Connect is a layer on top of OAuth2, the modifications to migrate the client code from OAuth2 to OpenID Connect are not significant, and are made by making use of the \emph{angular-auth-oidc-client} library~\cite{angular-auth-oidc-client}.
The flow remains the same: Glowing Bear obtains a JSON Web Token (JWT) from the OpenID Connect provider, which will then be embedded in the header of the HTTP requests to IRCT.

\subsubsection{IRCT Resources Support}
% todo: summary of GB supports for predicates / operations

\paragraph{Resources List}
After the user has successfully logged in, Glowing Bear requests the list of IRCT resources available and their properties.
Then the user chooses from the list which resource to use for the current session: it is possible to use only one resource at a time.
The selected resource and its properties are kept in the new \verb|IRCTResourceService| service that keeps and processes all the information about the resource returned by PIC-SURE.
The method \verb|ResourceService.getResources()| is added to retrieve the PIC-SURE resources with the following API call:
\begin{verbatim}
GET /rest/resourceService/resources
\end{verbatim}

Response:
\begin{verbatim}
[
  {
    "id": 1,
    "name": "resource name (e.g. i2b2-local)",
    "implementation": "resource type (which implementation is used, e.g. i2b2XML)",
    "relationships": [ supported relationships between tree nodes, e.g. CHILD ],
    "logicaloperators": [ "AND", "OR", "NOT" ],
    "predicates": [ supported predicates and their properties, e.g.: {
        "predicateName": "predicate name (e.g. CONTAINS)",
        "displayName": "displayed name (e.g. Contains)",
        "description": "description",
        "default": true if this predicate should be selected by default,
        "fields": [ {
            "name": "field name (e.g. By Encounter)",
            "path": "field code (to be used in query, e.g. ENCOUNTER)",
            "description": "By Encounter",
            "required": true,
            "dataTypes": [ data type of the value field(s) of this predicate ],
            "permittedValues": [ permitted values, if it categorical ]
          } ],
        "dataTypes": [ data types to which this predicate applies (e.g. STRING) ],
        "paths": [ paths to which this predicate applies (empty for all) ]
      } ],
    "selectOperations": [ supported operations for select (e.g. AGGREGATE) ],
    "selectFields": [ supported fields for the operations, e.g. COUNT for AGGREGATE ],
    "joins": [ ],
    "sorts": [ ],
    "processes": [ ],
    "visualization": [ ],
    "dataTypes": [ data types and their properties, e.g.: {
        "name": "name of the data type",
        "pattern": "regex to validate the value",
        "description": "description of the data type"
    } ]
  },
  ...
]
\end{verbatim}


\paragraph{Specific Features}
\verb|IRCTResourceService| provides methods that determine if some specific features are supported, which allows some features of Glowing Bear to be enabled or disabled:
\begin{itemize}
    \item \verb|supportsCounts()|: returns \emph{true} if queries of type \verb|SELECT COUNT| are supported, which enables the live counts display in the UI
    \item \verb|supportedCountsDimensions()|: if \verb|supportsCounts()| is \emph{true}, returns the countable dimensions (most commonly \emph{Patients} and \emph{Observations}).
    \item \verb|supportsNestedClauses()|: returns \emph{true} if the \emph{where} clause predicates \verb|CLAUSE_NEST| and \verb|CLAUSE_UNNEST| allowing nesting are supported
    \item \verb|| supports: min, max (others needed for GB?)
    \item \verb|supportsStudies()|: returns \emph{true} if queries of type \verb|SELECT STUDIES| are supported (todo: also clinical trials) (todo: also constraint or not)
    \item \verb|supportsPedigrees()|: returns \emph{true} if constraints based on pedigrees are supported
    \item \verb|supportsGetTreeWithDepth()|: returns \emph{true} if the tree can be retrieved with a specified depth (if the resource declare a tree relationship as \verb|CHILDREN-DEPTH-X|)
\end{itemize}

% todo: add for the data types capabilities, what does it return exactly? predicate?
% todo: add for shrine the only count (ie data export not supported)


\subparagraph{Studies}

% general + into tree
The tranSMART REST API v2 has several calls that are specific to studies, while the PIC-SURE API does not have a direct equivalent to this.
However since the studies are completely embedded within the concept tree, i.e. a concept belongs to one study or it is cross-study, they can simply be abstracted into the tree of entities exposed by PIC-SURE: we create a \verb|STUDY| data type for the tree entities (see~\ref{sec:gb-tree}).
\verb|TreeNodeService.isTreeNodeAStudy()| implements the recognition of the \verb|STUDY| data type.

% list of studies
If the resource supports it, \verb|ConstraintService.loadStudies()| loads the list of studies by calling \verb|ResourceService.getStudies()|, which is modified to use the following PIC-SURE call:
\begin{verbatim}
POST /rest/queryService/runQuery?full_response
{
  "select": [ {
    "operation": "STUDIES"
  } ],
  "alias": "get_studies"
}
\end{verbatim}

% todo: add pedigree (luke test to see how it works)



\subsubsection{Concepts Tree}
\label{sec:gb-tree}
% todo: check consistency for level of details

% modification of request (api call)
The API call in \verb|ResourceService.getTreeNodes()| is modified according to the following:
\begin{itemize}
     \item \verb|depth| parameter is replaced by \verb|relationship|: if the resource supports the retrieval of nodes with a depth more than one, then it will be achieved through a specific entities relationship API call \verb|CHILDREN-DEPTH-X|; 
    \item parameters \verb|hasCounts| and \verb|hasTags| are removed (these fields are always returned, although can be empty according to the resource implementation)
\end{itemize}

The API request becomes:
\begin{verbatim}
GET /rest/resourceService/path/<resource>/<path>/?relationship=<relationship>
\end{verbatim}

Response:
\begin{verbatim}
[
  {
    "pui": "/<resource>/<path>/",
    "name": "Concept internal name",
    "displayName": "Concept name",
    "description": "Concept description",
    "ontology": "Ontology Code",
    "ontologyId": "Concept ID in the ontology",
    "relationships": [ supported relationships ],
    "counts": {},
    "dataType": {
      "name": "Data type name",
      "pattern": "Validation Regex",
      "description": "Data type description"
    },
    "attributes": {
      "visualattributes": "Visual attributes",
      "customAttributeName": "customAttributeValue"
    }
  },
  ...
]
\end{verbatim}

The \verb|dataType| field allows to know which constraints defined in the resource can be applied, thus what options can be presented to the user when a query is constructed with the help of the \verb|IRCTResourceService|, see more details section~\ref{sec:designgbstep1}.
The \verb|visualattributes| field allows to modify the appearance of the concept in the UI, for example if it's a folder containing concept, or a leaf node. 
Its presence is optional so if it is absent, the appearance will stay as it is by default, this behavior is defined in the \verb|GbTreeNodesComponent| component.
The other fields can easily be mapped to original fields in Glowing Bear.

% modification relating no depth call possible
In \verb|TreeNodeService.loadTreeNodes()|, \verb|loadTreeNext()| is called to iteratively load the nodes.
\verb|loadTreeNext()| needs to be modified to account for \verb|ResourceService.getTreeNodes()| possibly not being able to load with a depth greater than one, meaning it must be called for every node of the tree.
This is determined using \verb|IRCTResourceService.supportsGetTreeWithDepth()|.
The difference between a node and a leaf is made with the use of the \verb|relationships| field: if the node supports the relationship \verb|CHILD|, it is a node for which children can be requested.

% about format of node JSON
\verb|TreeNodeService.processTreeNodes()| and \verb|processTreeNode()| process the received JSON to load it into the internal \verb|treeNodes| array containing the tree in memory, they should be adapted to fit the PIC-SURE JSON format.
This allows all the other parts of Glowing Bear that use the node to access the information needed.


\subsubsection{Query Step 1: Constraints}

% GB overall workflow for queries
The original Glowing Bear workflow for creating the constraints is the following: \\
\verb|GbConstraintComponent.onDrop()| processes the node being dropped in the query construction panel in the UI by calling \verb|ConstraintService.generateConstraintFromSelectedNode()| to generate the constraint based on the dropped node. \\
It uses \verb|ConstraintService.generateConstraintFromConstraintObject()| to construct the individual constraint objects.

The constraints generated in the step 1 of the query corresponds to the \emph{where} clauses of the PIC-SURE query: they define the criterion the resulting data must satisfy.
The components based on \verb|modules/gb-data-selection-module/constraint-component/GbConstraintComponent| and the models based on \verb|models/constraint-models/Constraint| correspond to the different PIC-SURE predicates that Glowing Bear supports.
Overall the Glowing Bear workflow stays the same at a high-level, but its implementation at the low-level undergoes significant changes to bring compatibility with PIC-SURE.

% logic
\verb|ConstraintService| is initialized with \verb|IRCTResourceService|: this allows the service to link the data types of the tree nodes with the constraints they support. \\
\verb|ConstraintService.generateConstraintFromConstraintObject()| is the core method of the constraint generation, and is thus completely re-implemented and is renamed \verb|generateConstraintFromDataType()|.
It is modified to take as input the data types coming from the PIC-SURE tree, and is using the \verb|IRCTResourceService| to get the constraints corresponding to the data types, returning a \verb|Constraint| object.
\verb|generateConstraintFromSelectedNode()| is modified to have two cases only: it is a queryable node, i.e. it has a data type, or not. If it has a data type it uses \verb|generateConstraintFromDataType()| to get the constraint, if not it calls itself recursively with the children nodes.

% data types supported
\verb|generateConstraintFromDataType()| supports the following PIC-SURE data types:
\begin{itemize}
\item Primitive
    \begin{itemize}
        \item Numeric types: \verb|INTEGER|, \verb|LONG|, \verb|FLOAT|, \verb|DOUBLE|
        \item Date types: \verb|DATE|, \verb|DATETIME|
        \item String type: \verb|STRING|
    \end{itemize}

\item Custom
    \begin{itemize}
        \item Enumerated type: \verb|ENUM_FIELD| and \verb|ENUM_VALUE| (enumerated value exposed through the tree and not as a value)
        \item Ontology concept type: \verb|CONCEPT| (simple concept without value)
        \item Study: \verb|STUDY| (restrict to a specific study)
        \item Pedigree: \verb|PEDIGREE| (constraint based on relationship, e.g. parents of another selection of patients)
    \end{itemize}
\end{itemize}


\paragraph{\emph{where} Models}

% constraint models
The way the constraints are represented internally need modification, as the nature of the tranSMART constraints and the PIC-SURE \emph{where} clauses are slightly different: they are more generic, but more importantly the supported predicate for each data type are known only at the runtime.
Constraints models in \verb|src/app/models/constraint-models/| are now not based on the type of the constraint, but on the predicate used for the constraint.
The interface \verb|Constraint| remains, but the members \verb|toQueryObjectWithSubselection()|, \verb|toQueryObjectWithoutSubselection()| and \verb|parent| are removed.
The equivalent of the subselection in PIC-SURE would be the dimension, but 
\begin{enumerate*}[label=(\arabic*)]
  \item it is defined by the resources themselves,
  \item it is integrated into the \emph{select} clauses, which is handled in the second step as it is not considered a constraint;
\end{enumerate*}
justifying the removal of those members.
They also now contain data about themselves specified by the IRCT resource: predicates name, description, paths and data types it applies to, its fields (name, code, description, required flag, data type and permitted values).

% constraint models JSON generation example
\verb|toQueryObject()| takes care of generating the JSON of the constraint: all the implementing methods now needs to generate the PIC-SURE \emph{where} clauses.
Example of two different \emph{where} clauses that would be produced by the corresponding \verb|toQueryObject()| methods:
\begin{verbatim}
{
    "field": {
        "pui": "/transmart/study1/Gender/Male/",
        "dataType": "ENUM_VALUE"
    },
    "predicate": "CONTAINS"
}

{
    "field": {
        "pui": "/transmart/study1/Age/",
        "dataType": "INTEGER"
    },
    "predicate": "CONSTRAIN_VALUE_NUMERIC",
    "fields": {
        "OPERATOR": "==",
        "CONSTRAINT": "5"
    }
}
\end{verbatim}


% ----------------------------------------------------------------------------------
\paragraph{Instantiating Constraints}
Because the predicates and the fields they have are known only at runtime, we create a service \verb|ConstraintFactoryService| that handles the instantiating of properly initialized \verb|Constraint| objects.
A method \verb|createConstraint()| taking as parameters the data type and and predicate returns the \verb|Constraint| object.
While some pre-defined predicates are supported by Glowing Bear (see list \ref{todo}), or even required for some features, not all can be supported. 
For this reason a generic \verb|Constraint| is created, that allows Glowing Bear to handle unknown constraints that resources might declare.

% list of types of constraints, based on the predicate they support
The difference constraint models with their associated predicate, that together support all the PIC-SURE data types listed in~\ref{sec:gb-predicates}, are listed below:
\begin{itemize}
    \item \verb|ConceptConstraint|: predicate \verb|CONSTRAINT_CONCEPT|, valid for \verb|ENUM_FIELD|, \verb|ENUM_VALUE|, \verb|CONCEPT| and all primitive types 
    \item \verb|FieldConstraint|: predicate \verb|CONSTRAINT_FIELD|, valid for arbitrary values of fields in dimensions (e.g. data types \verb|STUDY|, \verb|TRIAL_VISIT|), and used to create constraint based on observation date
    \item \verb|PedigreeConstraint|: predicate \verb|CONSTRAINT_PEDIGREE|, valid for pedigree data types
    \item \verb|PatientSetConstraint|: predicate \verb|CONSTRAINT_PATIENT_SET|, valid for patient set (imported through the UI)
\end{itemize}

Note that \verb|StudyConstraint| and \verb|TrialVisitConstraint| are merged within the new \verb|FieldConstraint|, similarly \verb|GbStudyConstraintComponent| into the new \verb|GbFieldConstraintComponent|.
The trial-visit logic form \verb|GbConceptConstraintComponent| is moved to \verb|GbFieldConstraintComponent|.
Note also that not all constraints are supported by all resources, the support is known by using \verb|IRCTResourceService.supports*()| methods. 

\subparagraph{Concept Constraint}
This is a simple constraint based on the presence of a concept and possibly its associated value.
A change from the original behavior is the way the values of the enumerated field are recuperated: this is done through the tree by looking at the data types, enumerated fields have a \verb|ENUM_FIELD| types, and its possible values are children of the node with the type \verb|ENUM_VALUE|.
Another change concerns the aggregates values, see~\ref{sec:gb-step1-aggregates} for more information.
The supported operators are \verb|==|, \verb|<=|, \verb|>=|, \verb|<|, \verb|>|, \verb|LIKE[exact]|, \verb|LIKE[begin]|, \verb|LIKE[end]| and \verb|LIKE[contains]|.

Example of concept \emph{where} clauses:
\begin{verbatim}
{
    "where": [ {
            "field": {
                "pui": "/transmart/study1/Age/",
                "dataType": "INTEGER"
            },
            "predicate": "CONSTRAIN_CONCEPT", 
            "fields": { "OPERATOR": ">=", "VALUE":"20" } 
        }, {
            "field": {
                "pui": "/transmart/study1/Age/",
                "dataType": "INTEGER"
            },
            "predicate": "CONSTRAIN_CONCEPT", 
            "fields": { "OPERATOR": "<=", "VALUE":"25" },
            "logicalOperator": "AND"
        }, {
            "field": {
                "pui": "/transmart/study1/Gender/Male/",
                "dataType": "ENUM_VALUE"
            },
            "predicate": "CONSTRAIN_CONCEPT"
        } ]
}
\end{verbatim}

\subparagraph{Field Constraint}
This new constraint allows to restrict according to the value of field in some dimension of the data.
It allows to query for a study, clinical-trial visit, observation date, and others.
It is implemented in the constraint model \verb|FieldConstraint| and the component \verb|GbFieldConstraintComponent|.

Example of field \emph{where} clauses generated:
\begin{verbatim}
{
    "where": [ {
            "predicate": "CONSTRAIN_FIELD", 
            "fields": { 
                "DIMENSION": "study", "FIELD":"study_id", 
                "OPERATOR": "==", "VALUE": "ORACLE_1000_PATIENT" 
            } 
        }, {
            "predicate": "CONSTRAIN_FIELD", 
            "fields": { 
                "DIMENSION": "trial_visit", "FIELD":"rel_time_num", 
                "OPERATOR": "==", "VALUE": "2" 
            },
            "logicalOperator": "AND"
        }, {
            "predicate": "CONSTRAIN_FIELD", 
            "fields": { 
                "DIMENSION": "observation", "FIELD":"start_date", 
                "OPERATOR": "<=", "VALUE": "2010-02-22" 
            },
            "logicalOperator": "AND"
        } ]
}
\end{verbatim}

\subparagraph{Pedigree Constraint}
Constraints based on pedigree are special in that they are based on other constraints (e.g. getting the parents of patients aged more than 50).
We add for them a predicate \verb|CONSTRAINT_PEDIGREE|, which has three fields:
\begin{itemize}
    \item \verb|TYPE|, required: list of permitted values which are either the type of pedigree (parents of, siblings of, etc.) or the indicator of the end of the pedigree constraints \verb|CONSTRAINT_END| (see example after)
    \item \verb|BIOLOGICAL|, optional, default to \verb|BOTH|: either \verb|YES|, \verb|NO| or \verb|BOTH|
    \item \verb|SHARE_HOUSEHOLD|, optional, default to \verb|BOTH|: either \verb|YES|, \verb|NO| or \verb|BOTH|
\end{itemize}

Example of a pedigree \emph{where} clause:
\begin{verbatim}
{
    "where": [
        {"predicate": "CONSTRAINT_PEDIGREE", "fields": { "TYPE": "PARENTS_OF", "BIOLOGICAL":"YES" } },
        <classic constraints>..., 
        {"predicate": "CONSTRAINT_PEDIGREE", "fields": { "TYPE": "CONSTRAINT_END" } }
    ]
}
\end{verbatim}

Similarly to other constraints, the logic construction is implemented into \verb|GbPedigreeConstraintComponent| and the model representing such a constraint is \verb|PedigreeConstraint|.
only enabled \verb|IRCTResourceService.supportsPedigree()|

\subparagraph{Patient Set Constraint}
Through the UI, the user of Glowing Bear can import a patient set and use it as a constraint, this handled by \verb|GbPatientSetConstraintComponent| and stored into a model \verb|PatientSetConstraint|, which are modified to adapt to the PIC-SURE format.
It supports either an array of patient identifiers, or the identifier of a patient set.

Example of patient set \emph{where} clauses:
\begin{verbatim}
{
    "where": [
        {"predicate": "CONSTRAINT_PATIENT_SET", "fields": { "PATIENT_SET_ID": "52" } },
        {"predicate": "CONSTRAINT_PATIENT_SET", "fields": { "PATIENT_IDS": "[2, 32, 96]" } }
    ]
}
\end{verbatim}


% ----------------------------------------------------------------------------------
\paragraph{Logical Operators}
Glowing Bear supports the definition of nested inclusion criteria, with the criteria belonging to the same group being linked by a logical operator \emph{AND} or \emph{OR}.
PIC-SURE allows queries with several \emph{where} clauses and lets each resource declares the logical operators it supports to link them. 
However the link between the clauses is flat, a clause defines its relationship with the previous clause: nested queries are not possible natively with PIC-SURE, but a workaround is presented below.

For resources that support nested queries, they declare the support for the \verb|NESTING| predicate, having a field called \verb|TYPE| with the permitted values \verb|START| and \verb|END|.
By using these it is possible for resources to support nested queries, see the following example for the methodology:
Consider the following nested query constructed in Glowing Bear:
\begin{verbatim}
    ((H AND B) OR (D AND S)) AND X AND (H OR F)
\end{verbatim}
It would have the PIC-SURE query with the following \emph{where} clauses:
\begin{verbatim}
{
    "where": [
        {"predicate": "NESTING", "fields": { "type": "START" } },
        {"predicate": "NESTING", "fields": { "type": "START" } },
        { H },
        { B, "logicalOperator": "AND" },
        {"predicate": "NESTING", "fields": { "type": "END" } },
        {"predicate": "NESTING", "fields": { "type": "START" }, "logicalOperator": "OR" },
        { D },
        { S, "logicalOperator": "AND" },
        {"predicate": "NESTING", "fields": { "type": "END" } },
        {"predicate": "NESTING", "fields": { "type": "END" } },
        { X, "logicalOperator": "AND" },
        {"predicate": "NESTING", "fields": { "type": "START" }, "logicalOperator": "AND" },
        { H },
        { F, "logicalOperator": "AND" },
        {"predicate": "NESTING", "fields": { "type": "END" } }
    ]
}
\end{verbatim}

\verb|CombinationConstraint|, \verb|GbConstraintComponent| and \verb|ConstraintService.generateConstraintFromConstraintObject()| are modified to 
\begin{itemize}
    \item support this construction by storing an array of \verb|Constraint|, appropriately setting their \verb|logicalOperator| fields and adding the nesting \emph{where} clauses;
    \item allowing or not the nesting of queries according to the resource capabilities.
\end{itemize}
Query nesting status is reflected in the UI by removing the \verb|add criterion| boxes for the attributes with a level equal to or lower than 1 if it is not supported.

% generation of the whole thing from outside
The method \verb|ConstraintService.generateSelectionConstraint()| is what is used by other parts of the code to generate the constraints defined in the first step in a format that fits the API call.
We rename it to \verb|generateWhereAttribute()| to fit the PIC-SURE jargon, and modify the method accordingly.
It returns a \verb|CombinationConstraint| as described in the previous paragraph.

\subparagraph{Negation}
The logical operator \verb|NOT| is at the same level as the \verb|AND| and \verb|OR|.
For this reason the resources declare all the following operators:
\begin{enumerate*}[label=(\arabic*)]
  \item \verb|AND|,
  \item \verb|OR|,
  \item \verb|NOT|,
  \item \verb|AND NOT|,
  \item \verb|OR NOT|.
\end{enumerate*}
Which allows all kinds of queries.


% ----------------------------------------------------------------------------------
\paragraph{User Interface}
When adding criterion at the step 1, the UI has to know what data type is the entity in order to know what input from the user is expected.
This behavior is implemented in the \verb|GbConstraintComponent| and its extending components.
These components are modified or removed to fit all the modifications previously described, to arrive at a state where there is one component for each of the supported predicates described section~\ref{todo}.
Additionally they use the information provided by \verb|IRCTResourceService| to:
\begin{itemize}
    \item offer to the user a list of the supported predicates to choose from,
    \item know what fields the predicate needs,
    \item enforce format of the fields input values with the regex or offer a dropdown list of permitted values, 
    \item enforce required or optional fields,
    \item display aggregates about the concept (such as the min, max, etc.).
\end{itemize}

The parent \verb|GbConstraintComponent| is modified to hold the data type of the dropped node, and allow for the switch between predicates (if multiple predicates are supported by the data type).
Then the extending components, one for each predicate (with the addition of the one for unknown predicates), are used according to the chosen predicate.

% todo: mention modifiers (but expose through tree)
% todo: optimization : \verb|ConstraintService.optimizeContraintObject()|
% todo: root constraint should it be mentionned? yes there will be no root, but an array, use the model for the and/or to hold it  
% todo: create model SelectClause (for count example: fields pui, dataType, Function, dimension)
% todo: rename constraint to whereclause
% todo: pedigree relation types can be requested as a list, should it go also with api, or should it go in resource def?


\subsubsection{Query Step 1: Aggregates}
\label{sec:gb-step1-aggregates}
%todo: model SelectClause

Glowing Bear does three kinds of aggregate queries: \emph{counts}, \emph{min} / \emph{max} and \emph{values}. 
\emph{Counts} queries are made when the user presses \emph{Update Counts} after modifying constraints (in step 1) or after modifying selected attributes for export (in step 2).
\emph{Min} / \emph{max} and \emph{values} queries are made when constructing constraints from the UI, to help the user the user by displaying some metadata.
The API calls and calling methods made are modified to use PIC-SURE as described below.
As support for aggregate \emph{select} calls is not mandatory for the resources, if the resource does not support it the related features are disabled (more info in section~\ref{sec:featuresdisable}).

\verb|ResourceService.getCounts()|, \verb|getStudies()| are merged into \verb|getAggregate()|.
This means that all the code calling those methods need to be adapted to fit the inputs and outputs of the new \verb|getAggregate()|.
This notably includes \verb|GbConceptConstraintComponent.initializeConstraints()|, \verb|QueryService.updateInclusionCounts()|, \verb|updateExclusionCounts()|, \verb|updateCounts_2()|, \verb|updateConceptsAndStudiesForSubjectSet()|, \verb|ConstraintService.loadStudies()|.

\verb|getAggregate()| becomes more generic and accepts the following arguments:
\begin{itemize}
    \item \verb|aggregateType|: \emph{count}, \emph{min}, \emph{max}, \emph{values}
    \item \verb|dimension|: among the dimensions declared by the resource
    \item \verb|pui|: optionally a concept path if it is relevant for the query
    \item \verb|dataType|: data type of the \verb|pui|
\end{itemize}

% todo: mention the where clause in example
Example of PIC-SURE aggregate \emph{select} clauses:
\begin{verbatim}
POST /rest/queryService/runQuery?full_response
{
  "select": [ {
    "field": { "pui": "/path/to/concept/", "dataType": "STRING" },
    "operation": "AGGREGATE",
    "fields": { "FUNCTION": "count",  "DIMENSION": "patient" }
  }, {
    "operation": "AGGREGATE",
    "fields": { "FUNCTION": "count", "DIMENSION": "observation" }
  }, {
    "field": { "pui": "/path/to/concept/", "dataType": "INTEGER" },
    "operation": "AGGREGATE",
    "fields": { "FUNCTION": "min" }
  }, {
    "field": { "pui": "/path/to/concept/", "dataType": "INTEGER" },
    "operation": "AGGREGATE",
    "fields": { "FUNCTION": "max" }
  }, {
    "operation": "AGGREGATE",
    "fields": { "FUNCTION": "values",  "DIMENSION": "study" }
  }  ],
  "where": [ <constraints> ],
  "alias": "<query_alias>"
}
\end{verbatim}


\subsubsection{Saving a Query}
On top of modifying the \verb|Query| model to fit the PIC-SURE format, only the API calls to handle query saving need to be modified, the calling code remains the same.
The IRCT implementation to save and re-use saved queries is not complete: it is originally possible to only save queries, but not list or load them. 
See section~\ref{sec:irctsavedqueries} for the additional implementation in IRCT to add these features.

% saveQuery
In \verb|ResourceService.saveQuery()| the API request becomes:
\begin{verbatim}
POST /rest/queryService/saveQuery
{
    "queryName": <query_name>,
    "query": {
        <query_body>
    }
}    
\end{verbatim}

Response:
\begin{verbatim}
{
    "queryId": <query_id>
}    
\end{verbatim}

% getQueries
In  \verb|ResourceService.getQueries()| the API request becomes:
\begin{verbatim}
GET /rest/queryService/queries
\end{verbatim}

Response:
\begin{verbatim}
{
    [
        "queryId": <query_id>,
        "queryName": <query_name>,
        "query": {
            <query_body>
        }
    ], [
        ...
    ],
    ...
}    
\end{verbatim}

% updateQuery
In  \verb|ResourceService.updateQuery()| the API request becomes:
\begin{verbatim}
PUT /rest/queryService/queries/<query_id>
{
    "queryName": <query_name>,
    "query": {
        <query_body>
    }
}
\end{verbatim}

Response:
\begin{verbatim}
{
    "message": <status_message>
} 
\end{verbatim}

% deleteQuery
In  \verb|ResourceService.deleteQuery()| the API request becomes:
\begin{verbatim}
DELETE /rest/queryService/queries/<query_id>
\end{verbatim}

Response:
\begin{verbatim}
{
    "message": <status_message>
} 
\end{verbatim}

% todo: restoreQuery()

\subsubsection{Query Step 2: Data Selection}

% overview
In the PIC-SURE paradigm, this step is about preparing the \emph{select} statement of the query: the output for step 3 is the added \emph{select} causes to the query.
The changes in this part are minimal, as they are mainly about the modification of the resulting JSON containing the concepts the user wishes to get as a result, but they represent the same information.

% modifications
Originally this information is stored in a \verb|CombinationConstraint|, with individual constraints linked by a \verb|OR|.
Here for this purpose we are creating a new \verb|PICSURESelectAttribute| model containing the different \emph{select} clauses, which for each clause holds the path of the concept and the associated data type.
For the sake of consistency the method \verb|ConstraintService.generateProjectionConstraint()| is renamed to \verb|generateSelectAttribute()| and returns a \verb|PICSURESelectAttribute|.
Some additional minor modifications are made in the methods using this, such as \verb|QueryService.updateCounts_2()|, \verb|updateExports()| and \verb|GbExportComponent.runExportJob()|.

% example
Example of \emph{select} clauses generated during the second step:
\begin{verbatim}
"select": [ {
    "field": {
        "pui": "/<resource>/Public Studies/CATEGORICAL_VALUES/Demography/Age/",
        "dataType": "INTEGER"
    }
    }, {
    "field": {
        "pui": "/<resource>/Public Studies/CATEGORICAL_VALUES/Demography/Gender/Male/",
        "dataType": "ENUM_VALUE"
    }
    }, {
    "field": {
        "pui": "/<resource>/Public Studies/CATEGORICAL_VALUES/Demography/Gender/Female/",
        "dataType": "ENUM_VALUE"
    }
} ]
\end{verbatim}


\subsubsection{Query Step 3:  Data Export}




% todo: data types for export? what is it exactly ? -> data format api call 


% tabularresults
% check how data table couljkd be done (process? join?)

% %Component orchestrating the step 3 is originally the \verb|GbExportComponent|


% GET /resultService/available: returns the list of available results (of the user)
% returns the result id and the status
% <<< GB does first the call to get job list

% GET /resultService/resultStatus/ID
% if problem: message field (always try to get it, but can be null)
% if OK, fields are: result id, status, startime, endtime, data type

% GET /resultService/availableFormats/ID
% returns list of formats for a specific result

% GET /resultService/result/ID/format?download=yes
% download can be put to no (content type will change, set yes for download from browser with clickable link)


% some formats may not be available, but could be implemented: do match and check with ward/ bo which to support

% --> match of the columns? possible to cancel in irct?NO, status returned ? YES

% GB original: 
% /file\_formats
% /data\_formats


\subsection{IRCT Resources Implementation}
some to be modified, some to be implemented

- add support for shrine/medco with additional JAR packaged and put in wildfly
- add systems (by type) with pq-psql functions

resources modficiatons: add the agreggates (i2b2 just count, avg/min/max seems to be complicated? check it out)
i2b2: no select (currently), because it is mainly about the constraints: where clauses

importatn to specify what is done with minimal set of things supported

--> include datatype in query: saves a req to tree node
\paragraph{i2b2}

\paragraph{SHRINE}

\paragraph{tranSMART 16.2}

\paragraph{tranSMART 17.1}
last step is transmart 17.1 as connector, because it is if time allows


%\subsection{Current Status of Softwares}
%\subsection{Glowing Bear}
%desc of how it works
resource info in db -> example on how to do it with i2b2
through the api resourceService/resources get us all the resources and their capabilities(by type, but we want query for now i guess?)
define:
- predicates
- relationships
- the entities also define relationships, what is it exactly?
-> for GB we would need a minimum set of capabilities??

-> study should become just a parameter of the tree entity, but we shouldnt care about it
-> how / at which stage implement that in Gb?

edu.harvard.hms.dbmi.bd2k.irct.cl.rest;
classes implementing the REST API, using javax.ws.rs / JAX-RS: Java API for RESTful Web Services

---

-- irct --
version from github to select: which? there seem to be a new query param (commit on feb 2) only\_count, which may prove valuable for GB << important question to solve, check out a specific commit? last release is not recent enough as of now 

--> in the queryesrvice, when running query, there is a parameter "only\_count" that exists (in the later version)
it is added to the metadata of the query, to be processed by the RI (i guess support not mandatory) 
-> to have less processing, use it from GB!

select aggregate (count), they exist, check out: https://github.com/hms-dbmi/IRCT/blob/ae31f79ef2015bc6ae349e30e2a6652a22141b07/IRCT-RI/src/main/resources/SciDB.sql

aggregate is a type of select, and count is a type of aggregate, totally OK to do that 



--Resources--
does a lib in java to talk to transmart rest v2 exists? would be nice

todo: i2b2 parsing of and/or check notes

todo: transmart cache the ontology because depth can be specified

implekmentaion of transmart: study as first layer? no just the tree presentede by transmart

define interface for java / sql skeleton for GlowingBearFeatureName (counts, etc.)


RI transmart: thourhg the path, if within study: study is queried, if cross-study: no study queried, basically do as the constraint is specifying
+ to find the study associated to a concept, simply go up, or keep in cache a list of studies
Moreover the tree concept of tranSMART has at its root the studies
expose in tree as DIMENSION or as STUDY? --> dimension (like this lcinical trial also supported)

todo transmart: clauses nest / unnest
todo transmart: study data type
todo transmart: studies list, select operation

% todo: in irct modifs: add query name to the saved queries / add getQueries that returns the whole queries / add getQuery/id with PUT, DELETE, methods


% todo: config of irct: in appendix? 

irct tree impl.: transmart include study
i2b2 include modifiers


from transmart api: OK to use concept path
 "type": "concept",
                "path": "\\Public Studies\\EHR\\Diagnosis\\",


---
i2b2 parse and or:
Y OR Z OR (A AND B)
(Y OR Z OR A) AND (Y OR Z OR B)

--> 1 lvl only nesting
todo: how to enforce genericly this structure in the UI? what is possible to do in UI?

---
enum / study / modifier :TREE